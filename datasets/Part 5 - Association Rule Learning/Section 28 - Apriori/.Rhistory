tinytex::install_tinytex()
install.packages("tidyverse")
install.packages(c("boot", "class", "cluster", "codetools", "farver", "isoband", "KernSmooth", "lattice", "MASS", "Matrix", "mgcv", "nlme", "nnet", "ps", "spatial", "survival", "tidyr"))
knitr::opts_chunk$set(echo = TRUE)
str(datacrab)
install.packages("Rlab")
library(Rlab)
library(reticulate)
py_install(matplotlib)
py_install(qt)
help()
library(Rlab)
library(reticulate)
library(reticulate)
install.packages("Rlab")
print("Hello World")
dataset = read.csv('Data.')
dataset = read.csv('Data.csv')
knitr::opts_chunk$set(echo = TRUE)
dataset = read.csv('Data.csv')
View(dataset)
View(dataset)
knitr::opts_chunk$set(echo = TRUE)
dataset = read.csv('Data.csv')
dataset$Age = ifelse(is.na(dataset$Age), ave(dataset$Age, FUN = function(x) mean(x,na.rm=TRUE)),dataset$Age)
View(dataset)
View(dataset)
knitr::opts_chunk$set(echo = TRUE)
dataset = read.csv('Data.csv')
dataset$Age = ifelse(is.na(dataset$Age), ave(dataset$Age, FUN = function(x) mean(x,na.rm=TRUE)),dataset$Age)
dataset$Salary = ifelse(is.na(dataset$Salary), ave(dataset$Salary, FUN = function(x) mean(x,na.rm=TRUE)),dataset$Salary)
View(dataset)
View(dataset)
setwd("D:/Desarrollo/GitHubForks/machinelearning-az/datasets/Part 4 - Clustering/Section 25 - Hierarchical Clustering")
dataset = read.csv('Mall_Customers.csv')
X = dataset[, 4:5]
# Utilizar el dendrograma
dendrogram = hclust(dist(X,method="euclidean"),
method="ward.D")
plot(dendrogram,
main="Dendrograma",
xlab="Clientes Centro Comercial",
ylab="Distancia euclidea")
hc = hclust(dist(X,method="euclidean"),
method="ward.D")
y_hc = cutree(hc,k=5)
library(cluster)
clusplot(X,
y_hc,
lines=0,
shade=TRUE,
color=TRUE,
labels=2,
plotchar=FALSE,
span=TRUE,
main="Clustering de clientes con cluster jerárquico",
xlab="Ingresos anuales",
ylab="Score (1-100)")
dataset = read.csv('Mall_Customers.csv')
X = dataset[, 3:5]
# Utilizar el dendrograma
dendrogram = hclust(dist(X,method="euclidean"),
method="ward.D")
plot(dendrogram,
main="Dendrograma",
xlab="Clientes Centro Comercial",
ylab="Distancia euclidea")
dataset = read.csv('Mall_Customers.csv')
X = dataset[, 4:5]
# Utilizar el dendrograma
dendrogram = hclust(dist(X,method="euclidean"),
method="ward.D")
plot(dendrogram,
main="Dendrograma",
xlab="Clientes Centro Comercial",
ylab="Distancia euclidea")
# Ajustar clustering jerárquico - Elegimos el K = 5
hc = hclust(dist(X,method="euclidean"),
method="ward.D")
y_hc = cutree(hc,k=5)
# VisualizaciÃ³n de clusters
library(cluster)
clusplot(X,
y_hc,
lines=0,
shade=TRUE,
color=TRUE,
labels=2,
plotchar=FALSE,
span=TRUE,
main="Clustering de clientes con cluster jerárquico",
xlab="Ingresos anuales",
ylab="Score (1-100)")
setwd("D:/Desarrollo/GitHubForks/machinelearning-az/datasets/Part 5 - Association Rule Learning/Section 28 - Apriori")
dataset = read.csv('Mall_Customers.csv')
X = dataset[, 4:5]
dataset = read.csv('Market_Basket_Optimisation.csv')
X = dataset[, 4:5]
View(dataset)
View(dataset)
View(X)
dataset = read.csv('Market_Basket_Optimisation.csv',headers=FALSE)
dataset = read.csv('Market_Basket_Optimisation.csv',header=FALSE)
install.packages("arules")
# Preprocesado de datos ... Tendremos una matriz Sparse con muchos ceros, dado que el dataset tiene mucho vacío
library(arules)
dataset_orig = read.csv('Market_Basket_Optimisation.csv',header=FALSE)
dataset = read.transaction
View(dataset)
View(dataset)
dataset = read.transactions('Market_Basket_Optimisation.csv', sep=",")
View(dataset)
View(dataset)
dataset = read.transactions('Market_Basket_Optimisation.csv', sep=",", rm.duplicates = TRUE)
View(dataset)
summary(dataset)
itemFrequencyPlot(dataset,topN=100)
itemFrequencyPlot(dataset,topN=20)
# Entrenar algoritmo de Apriori con el dataset
rules = apriori(data = dataset,
parameter = list(support = 0.003, confidence=0.8))
View(rules)
View(rules)
# Entrenar algoritmo de Apriori con el dataset
rules = apriori(data = dataset,
parameter = list(support = 0.003, confidence=0.4))
# Entrenar algoritmo de Apriori con el dataset
rules = apriori(data = dataset,
parameter = list(support = 0.003, confidence=0.5))
# Entrenar algoritmo de Apriori con el dataset
rules = apriori(data = dataset,
parameter = list(support = 0.003, confidence=0.4))
# Visualización de los resultados
inspect(rules[1:10])
# Visualización de los resultados
inspect(sort(rules, by='lift')[1:10])
# Entrenar algoritmo de Apriori con el dataset
rules = apriori(data = dataset,
parameter = list(support = 0.003, confidence=0.5))
# Visualización de los resultados
inspect(sort(rules, by='lift')[1:10])
# Entrenar algoritmo de Apriori con el dataset
rules = apriori(data = dataset,
parameter = list(support = 0.003, confidence=0.2))
# Visualización de los resultados
inspect(sort(rules, by='lift')[1:10])
# Entrenar algoritmo de Apriori con el dataset
rules = apriori(data = dataset,
parameter = list(support = 0.01, confidence=0.2))
# Visualización de los resultados
inspect(sort(rules, by='lift')[1:10])
dataset_orig = read.csv('Market_Basket_Optimisation.csv',header=FALSE)
# Preprocesado de datos ... Tendremos una matriz Sparse con muchos ceros, dado que el dataset tiene mucho vacÃ­o
library(arules)
dataset = read.transactions('Market_Basket_Optimisation.csv', sep=",", rm.duplicates = TRUE)
itemFrequencyPlot(dataset,topN=20)
# Entrenar algoritmo de Apriori con el dataset
rules = apriori(data = dataset,
parameter = list(support = 0.01, confidence=0.2))
# VisualizaciÃ³n de los resultados
inspect(sort(rules, by='lift')[1:10])
library(arules)
library(arulesViz)
path <- "D:/Desarrollo/GitHubForks/machinelearning-az/datasets/Part 5 - Association Rule Learning/Section 28 - Apriori"
trans <- read.transactions(
file = paste0(path, "Market_Basket_Optimisation.csv"),
sep = ",",
rm.duplicates = TRUE
)
path <- "D:/Desarrollo/GitHubForks/machinelearning-az/datasets/Part 5 - Association Rule Learning/Section 28 - Apriori/"
trans <- read.transactions(
file = paste0(path, "Market_Basket_Optimisation.csv"),
sep = ",",
rm.duplicates = TRUE
)
# apriori algoirthm ------------------------------------------------------
rules <- apriori(
data = trans,
parameter = list(support = 0.004, confidence = 0.2)
)
plot(rules, method = "graph", engine = "htmlwidget")
